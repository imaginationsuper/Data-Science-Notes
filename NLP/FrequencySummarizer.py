# coding: uft-8

from nltk.tokenize import sent_tokenize, word_tokenize # tokenize text into sentences and words
from nltk.corpus import stopwords # find and filter very common words

from collections import defaultdict # dictionary with default value

from string import punctuation # punctuation symbols

from heapq import nlargest # return n largest elements in given list

